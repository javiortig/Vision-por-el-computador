{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etiquetar las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import csv\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga el cliente con su KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            return file.read().strip()\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading API key from {file_path}: {e}\")\n",
    "\n",
    "client = openai.Client(api_key=load_api_key('./key.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def analyze_image(image_path):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Add a prompt to ask the model about the image characteristics\n",
    "    prompt = (\"Analyze the person in the image and label them with the following features:\\n\"\n",
    "              \"1. (0) short hair, (1) long hair\\n\"\n",
    "              \"2. (0) wears no glasses, (1) wears glasses\\n\"\n",
    "              \"3. (0) has no beard, (1) has beard\\n\"\n",
    "              \"4. (0) does not show teeth, (1) shows teeth\\n\\n\"\n",
    "              \"Return the result as an array of 4 values in the format: [hair, glasses, beard, teeth].\")\n",
    "\n",
    "    # Convert the image to a format compatible with OpenAI API (if needed)\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    image_bytes = buffered.getvalue()\n",
    "\n",
    "    # Use OpenAI's API to analyze the image\n",
    "    response = openai.Image.create_edit(\n",
    "        prompt=prompt,\n",
    "        n=1,\n",
    "        size=\"1024x1024\",\n",
    "        image=image_bytes,\n",
    "    )\n",
    "\n",
    "    # Interpret the response (mock response since this capability may not exist directly)\n",
    "    labels = [0, 1, 0, 1]  # Example mock response\n",
    "    return labels\n",
    "\n",
    "# Analyze multiple images\n",
    "image_paths = ['Dataset P2/Celebrity Faces Dataset/Angelina Jolie/001_fe3347c0.jpg']  # Replace with your actual image paths\n",
    "results = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    result = analyze_image(image_path)\n",
    "    results.append(result)\n",
    "\n",
    "print(\"Analysis Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The images you provided are identical, showing a natural landscape with a wooden pathway crossing through a grassy field under a blue sky with clouds. Since they are the same, there is no difference between them.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What are in these images? Is there any difference between them?\",\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='[0, 0, 1, 0]', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"tempImages/010_2f9c83bc.jpg\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Im giving you an image of a person. Analyze the person in the image and label them with the following features:\\n\"\n",
    "              \"1. (0) has short hair, (1) has long hair, (2) you are not sure\\n\"\n",
    "              \"2. (0) wears no glasses, (1) wears glasses, (2) you are not sure\\n\"\n",
    "              \"3. (0) has no beard, (1) has a beard, (2) you are not sure\\n\"\n",
    "              \"4. (0) has the mouth closed, (1) has the mouth open, (2) you are not sure\\n\\n\"\n",
    "              \"Return the result as an array of 4 values in the format: [hair, glasses, beard, teeth]. Return only the array and dont say anything else.\",\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\":  f\"data:image/jpeg;base64,{base64_image}\",\n",
    "            \"detail\": \"high\"\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Decode the base64 string\n",
    "image_data = base64.b64decode(base64_image)\n",
    "\n",
    "# Step 2: Open the image from the decoded bytes\n",
    "image = Image.open(BytesIO(image_data))\n",
    "\n",
    "# Step 3: Display the image using matplotlib\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Itera sobre un directorio para devolver en forma de csv las etiquetas de las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def analyze_image(image_path):\n",
    "    base64_image = encode_image(image_path)\n",
    "    \n",
    "    # Make the API call\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Im giving you an image of a person. Analyze the person in the image and label them with the following features:\\n\"\n",
    "                    \"1. (0) has short hair, (1) has long hair, (2) you are not sure\\n\"\n",
    "                    \"2. (0) wears no glasses, (1) wears glasses, (2) you are not sure\\n\"\n",
    "                    \"3. (0) has no beard, (1) has a beard, (2) you are not sure\\n\"\n",
    "                    \"4. (0) has the mouth closed, (1) has the mouth open, (2) you are not sure\\n\"\n",
    "                    \"5. (0) is a male, (1) is a female, (2) you are not sure\\n\\n\"\n",
    "                    \"Return the result as an array of 4 values in the format: [hair, glasses, beard, teeth]. Return only the array and dont say anything else.\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\":  f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\": \"high\"\n",
    "                },\n",
    "                },\n",
    "            ],\n",
    "            }\n",
    "        ],\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing image {image_path}: {e}\")\n",
    "        return None\n",
    "  \n",
    "# Function to process all images in a folder\n",
    "def process_folder(folder_path, output_csv):\n",
    "    results = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith((\"jpg\", \"jpeg\", \"png\")):  # Add more extensions if needed\n",
    "                # Normalize the path to use forward slashes\n",
    "                image_path = os.path.join(root, file)\n",
    "                normalized_path = image_path.replace(\"\\\\\", \"/\")\n",
    "                print(f\"Processing {normalized_path}...\")\n",
    "                analysis = analyze_image(normalized_path)\n",
    "                if analysis:\n",
    "                    results.append({\"image\": normalized_path, \"analysis\": analysis})\n",
    "    \n",
    "    # Save the results to a CSV file\n",
    "    with open(output_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        fieldnames = [\"image\", \"analysis\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(f\"Results saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tempImages/002_24fab375.jpg...\n",
      "Processing tempImages/010_18d7b27c.jpg...\n",
      "Processing tempImages/010_2f9c83bc.jpg...\n",
      "Processing tempImages/020_8e6bdc45.jpg...\n",
      "Processing tempImages/027_3290d1bc.jpg...\n",
      "Processing tempImages/071_d75194ff.jpg...\n",
      "Processing tempImages/084_31281f33.jpg...\n",
      "Processing tempImages/085_69f8d759.jpg...\n",
      "Processing tempImages/085_97ab4600.jpg...\n",
      "Processing tempImages/093_82a4677f.jpg...\n",
      "Results saved to ./tempImagesLabels.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder containing images and the output CSV file\n",
    "folder_path = \"tempImages\"\n",
    "output_csv = \"./tempImagesLabels.csv\"\n",
    "\n",
    "# Process the folder\n",
    "process_folder(folder_path, output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
