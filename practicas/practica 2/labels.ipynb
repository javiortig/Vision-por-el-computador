{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etiquetar las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import csv\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga el cliente con su KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            return file.read().strip()\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading API key from {file_path}: {e}\")\n",
    "\n",
    "client = openai.Client(api_key=load_api_key('./key.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def analyze_image(image_path):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Add a prompt to ask the model about the image characteristics\n",
    "    prompt = (\"Analyze the person in the image and label them with the following features:\\n\"\n",
    "              \"1. (0) short hair, (1) long hair\\n\"\n",
    "              \"2. (0) wears no glasses, (1) wears glasses\\n\"\n",
    "              \"3. (0) has no beard, (1) has beard\\n\"\n",
    "              \"4. (0) does not show teeth, (1) shows teeth\\n\\n\"\n",
    "              \"Return the result as an array of 4 values in the format: [hair, glasses, beard, teeth].\")\n",
    "\n",
    "    # Convert the image to a format compatible with OpenAI API (if needed)\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    image_bytes = buffered.getvalue()\n",
    "\n",
    "    # Use OpenAI's API to analyze the image\n",
    "    response = openai.Image.create_edit(\n",
    "        prompt=prompt,\n",
    "        n=1,\n",
    "        size=\"1024x1024\",\n",
    "        image=image_bytes,\n",
    "    )\n",
    "\n",
    "    # Interpret the response (mock response since this capability may not exist directly)\n",
    "    labels = [0, 1, 0, 1]  # Example mock response\n",
    "    return labels\n",
    "\n",
    "# Analyze multiple images\n",
    "image_paths = ['Dataset P2/Celebrity Faces Dataset/Angelina Jolie/001_fe3347c0.jpg']  # Replace with your actual image paths\n",
    "results = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    result = analyze_image(image_path)\n",
    "    results.append(result)\n",
    "\n",
    "print(\"Analysis Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The images you provided are identical, showing a natural landscape with a wooden pathway crossing through a grassy field under a blue sky with clouds. Since they are the same, there is no difference between them.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What are in these images? Is there any difference between them?\",\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='[0, 0, 1, 0]', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"tempImages/010_2f9c83bc.jpg\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Im giving you an image of a person. Analyze the person in the image and label them with the following features:\\n\"\n",
    "              \"1. (0) has short hair, (1) has long hair, (2) you are not sure\\n\"\n",
    "              \"2. (0) wears no glasses, (1) wears glasses, (2) you are not sure\\n\"\n",
    "              \"3. (0) has no beard, (1) has a beard, (2) you are not sure\\n\"\n",
    "              \"4. (0) has the mouth closed, (1) has the mouth open, (2) you are not sure\\n\\n\"\n",
    "              \"Return the result as an array of 4 values in the format: [hair, glasses, beard, teeth]. Return only the array and dont say anything else.\",\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\":  f\"data:image/jpeg;base64,{base64_image}\",\n",
    "            \"detail\": \"high\"\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Decode the base64 string\n",
    "image_data = base64.b64decode(base64_image)\n",
    "\n",
    "# Step 2: Open the image from the decoded bytes\n",
    "image = Image.open(BytesIO(image_data))\n",
    "\n",
    "# Step 3: Display the image using matplotlib\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Itera sobre un directorio para devolver en forma de csv las etiquetas de las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def analyze_image(image_path):\n",
    "    base64_image = encode_image(image_path)\n",
    "    \n",
    "    # Make the API call\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Im giving you an image of a person. Analyze the person in the image and label them with the following features:\\n\"\n",
    "                    \"1. (0) has short hair, (1) has long hair\\n\"\n",
    "                    \"2. (0) wears no glasses, (1) wears glasses\\n\"\n",
    "                    \"3. (0) has no beard, (1) has a beard\\n\"\n",
    "                    \"4. (0) is a male, (1) is a female\\n\"\n",
    "                    \"5. (0) Is not wearing jewelry, (1) is wearing jewelry\\n\"\n",
    "                    \"Return the result as an array of 5 values in the format: [hair, glasses, beard, gender, jewelry]. Return only the array and dont say anything else.\",\n",
    "                },\n",
    "                {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\":  f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\": \"high\"\n",
    "                },\n",
    "                },\n",
    "            ],\n",
    "            }\n",
    "        ],\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing image {image_path}: {e}\")\n",
    "        return None\n",
    "  \n",
    "# Function to process all images in a folder\n",
    "def process_folder(folder_path, output_csv):\n",
    "    results = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith((\"jpg\", \"jpeg\", \"png\")):  # Add more extensions if needed\n",
    "                # Normalize the path to use forward slashes\n",
    "                image_path = os.path.join(root, file)\n",
    "                normalized_path = image_path.replace(\"\\\\\", \"/\")\n",
    "                print(f\"Processing {normalized_path}...\")\n",
    "                analysis = analyze_image(normalized_path)\n",
    "                if analysis:\n",
    "                    results.append({\"image\": normalized_path, \"analysis\": analysis})\n",
    "    \n",
    "    # Save the results to a CSV file\n",
    "    with open(output_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        fieldnames = [\"image\", \"analysis\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(f\"Results saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/001_beebcee2.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/002_078f6fe5.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/003_936c5a43.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/004_af9b4c7c.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/005_37066c18.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/006_bbb6978e.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/007_9656ae64.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/008_cdaf39e7.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/009_a023db5b.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/010_8bd7dba1.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/011_0e0e8b1c.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/012_19e90fb6.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/013_19a43131.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/014_f512d81c.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/015_8da65114.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/016_d9c576a4.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/017_bb6ad7d6.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/018_d5d389eb.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/019_33ab99af.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/020_8e6bdc45.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/021_3cf2aa92.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/022_c9c4cb9f.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/023_cb306a1a.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/024_b222784a.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/025_0dc3ad3d.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/026_4f5bfb2c.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/027_803986e2.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/028_05df393f.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/029_09dcae68.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/030_df8c8fad.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/031_7ad763d7.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/032_2899cee6.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/033_241ed413.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/034_32b04ae9.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/035_9e22f213.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/036_8751d89b.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/037_17e4f89a.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/038_b28dda4c.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/039_3daa67cf.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/040_630a0d6a.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/041_bcfa1766.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/042_f6cff42f.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/043_33815e76.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/044_988edbe9.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/045_810b690c.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/046_6d5b1ed6.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/047_dc7e1839.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/048_bf9c2b11.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/049_15a71c48.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/050_f5bd72ba.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/051_1f3aede9.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/052_f15c0c78.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/053_8405b30f.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/054_cbee29ae.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/055_f9cbb53e.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/056_abd6e06b.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/057_faaa39ed.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/058_38b80eed.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/059_181bfc6b.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/060_8bb5cac3.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/061_4385aa8d.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/062_07fcfec7.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/063_46f560ca.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/064_88de03f4.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/065_5cb55293.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/066_5d45a68f.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/067_9e09ea61.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/068_b778f382.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/069_80468bd5.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/070_6743629d.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/071_5f7cdaaf.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/072_4a17b7fb.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/073_f04cd664.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/074_61fe25d9.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/075_65ffca63.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/076_d36850ba.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/077_eb907a5f.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/078_44637281.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/079_8575a4bc.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/080_94d3ede6.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/081_8dc3b149.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/082_ed9a24cc.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/083_a0692bc1.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/084_0d8b77bc.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/085_97ab4600.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/086_bd951ea7.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/087_6eba84a6.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/088_d6c5d9f4.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/089_97f39eb8.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/090_e959664a.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/091_082508dd.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/092_498e6999.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/093_dc555290.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/094_664a03cd.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/095_8a2dfab4.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/096_0881f6e7.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/097_5c18be93.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/098_6f416b6a.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/099_d652e3b6.jpg...\n",
      "Processing Dataset P2/Celebrity Faces Dataset/Will Smith/100_89cbf87f.jpg...\n",
      "Results saved to labels/Will Smith.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder containing images and the output CSV file\n",
    "folder_path = \"Dataset P2\\Celebrity Faces Dataset\\Will Smith\"\n",
    "output_csv = \"labels/Will Smith.csv\"\n",
    "\n",
    "# Process the folder\n",
    "process_folder(folder_path, output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
